import os
import json
import asyncio
from typing import Optional, Dict, Any
from langchain_openai import ChatOpenAI
from dotenv import load_dotenv
from app.chatbot.tool_agents.tools import LawGoKRTavilySearch
from app.chatbot.tool_agents.utils.utils import insert_hyperlinks_into_text
from app.chatbot.memory.global_cache import memory  # ConversationBufferMemory ì¸ìŠ¤í„´ìŠ¤
from app.chatbot.tool_agents.tools import async_ES_search

# ê¸€ë¡œë²Œ ìºì‹œ ê¸°ëŠ¥: í…œí”Œë¦¿ì„ ì‹œìŠ¤í…œ ë©”ì‹œì§€ë¡œ ì €ì¥í•˜ê³  ì¡°íšŒí•˜ëŠ” í•¨ìˆ˜ë“¤
from app.chatbot.memory.global_cache import (
    retrieve_template_from_memory,
)

load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")


def load_llm():
    return ChatOpenAI(
        model="gpt-3.5-turbo",
        api_key=OPENAI_API_KEY,
        temperature=0.3,
        max_tokens=1024,
    )


class AskHumanAgent:
    def __init__(self):
        self.llm = load_llm()
        self.tavily_search = LawGoKRTavilySearch()

# def build_mcq_prompt_full(self, user_query, llm1_answer, template_data, yes_count):
#     # ì €ì¥ëœ ì¤‘ê°„ ë°ì´í„°ê°€ ìˆì„ ê²½ìš° ì´ë¥¼ ì‚¬ìš©í•˜ì—¬ í”„ë¡¬í”„íŠ¸ë¥¼ êµ¬ì„±
#     template = template_data.get("template", {}) if template_data else {}
#     strategy = template_data.get("strategy", {}) if template_data else {}
#     precedent = template_data.get("precedent", {}) if template_data else {}

#     summary_with_links = insert_hyperlinks_into_text(
#         template.get("summary", ""), template.get("hyperlinks", [])
#     )
#     explanation_with_links = insert_hyperlinks_into_text(
#         template.get("explanation", ""), template.get("hyperlinks", [])
#     )
#     hyperlinks_text = "\n".join(
#         f"- {link['label']}: {link['url']}" for link in template.get("hyperlinks", [])
#     )
#     strategy_decision_tree = "\n".join(strategy.get("decision_tree", []))
#     precedent_summary = precedent.get("summary", "íŒë¡€ ìš”ì•½ ì—†ìŒ")
#     precedent_link = precedent.get("casenote_url", "ë§í¬ ì—†ìŒ")
#     precedent_meta = f"{precedent.get('court', '')} / {precedent.get('j_date', '')} / {precedent.get('title', '')}"

#     # ğŸ” ES ê²°ê³¼ê°€ ìˆì„ ê²½ìš° í”„ë¡¬í”„íŠ¸ì— í¬í•¨
#     es_results = template_data.get("es_results", [])
#     es_context = ""
#     if es_results:
#         es_context += "\n[ES ìœ ì‚¬ ìƒë‹´]\n"
#         for i, item in enumerate(es_results, start=1):
#             es_context += f"\nğŸ“Œ [{i}ë²ˆ ìƒë‹´]\n"
#             es_context += f"- ì œëª©(title): {item.get('title', '')}\n"
#             es_context += f"- ì§ˆë¬¸(question): {item.get('question', '')}\n"
#             es_context += f"- ë‹µë³€(answer): {item.get('answer', '')}\n"

#     # ConversationBufferMemory ë‚´ ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¡°íšŒ
#     memory.load_memory_variables({}).get("chat_history", "")

#     prompt = f"""
# ë‹¹ì‹ ì€ ë²•ë¥  ìƒë‹´ì„ ìƒì„±í•˜ëŠ” ê³ ê¸‰ AIì…ë‹ˆë‹¤.

# [ì‚¬ìš©ì ì§ˆë¬¸]
# {user_query}

# {es_context}

# [ìš”ì•½]
# {summary_with_links}

# [ì„¤ëª…]
# {explanation_with_links}

# [ì°¸ê³  ì§ˆë¬¸]
# {template.get("ref_question", "í•´ë‹¹ ì—†ìŒ")}

# [í•˜ì´í¼ë§í¬]
# {hyperlinks_text}

# [ì „ëµ ìš”ì•½]
# {strategy.get("final_strategy_summary", "")}

# [ì‘ë‹µ êµ¬ì„± ì „ëµ]
# - ë§íˆ¬: {strategy.get("tone", "")}
# - íë¦„: {strategy.get("structure", "")}
# - ì¡°ê±´ íë¦„ë„:
# {strategy_decision_tree}

# [ì¶”ì²œ ë§í¬]
# {json.dumps(strategy.get("recommended_links", []), ensure_ascii=False)}

# [ì¶”ê°€ëœ íŒë¡€ ìš”ì•½]
# - {precedent_summary}
# - ë§í¬: {precedent_link}
# - ì •ë³´: {precedent_meta}

# ğŸ¯ ì‘ì—…:
# - ì´ì „ ëŒ€í™”ì™€ ì´ì–´ì§€ëŠ” ìœ„ ë‚´ìš©ì„ ë°˜ì˜í•˜ì—¬, ì‚¬ìš©ìê°€ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ë²•ë¥  ìƒë‹´ì„ ìƒì„±í•˜ì„¸ìš”.
# - ê° í•­ëª©ì€ ì‹¤ì œ ìƒí™©ì„ ë°˜ì˜í•˜ë©°, ì‚¬ìš©ìê°€ ìì‹ ì˜ ìƒí™©ì— ë§ëŠ” ì„ íƒì§€ë¥¼ ì´í•´í•  ìˆ˜ ìˆê²Œ êµ¬ì„±í•´ì•¼ í•©ë‹ˆë‹¤.
# """
#     return prompt


    async def build_mcq_prompt_full(
        self, user_query, llm1_answer, template_data, yes_count
    ):
        template = template_data.get("template", {}) if template_data else {}
        strategy = template_data.get("strategy", {}) if template_data else {}
        precedent = template_data.get("precedent", {}) if template_data else {}

        summary_with_links = insert_hyperlinks_into_text(
            template.get("summary", ""), template.get("hyperlinks", [])
        )
        explanation_with_links = insert_hyperlinks_into_text(
            template.get("explanation", ""), template.get("hyperlinks", [])
        )
        hyperlinks_text = "\n".join(
            f"- {link['label']}: {link['url']}" for link in template.get("hyperlinks", [])
        )
        strategy_decision_tree = "\n".join(strategy.get("decision_tree", []))
        precedent_summary = precedent.get("summary", "íŒë¡€ ìš”ì•½ ì—†ìŒ")
        precedent_link = precedent.get("casenote_url", "ë§í¬ ì—†ìŒ")
        precedent_meta = f"{precedent.get('court', '')} / {precedent.get('j_date', '')} / {precedent.get('title', '')}"

        # âœ… es_resultsê°€ ì—†ìœ¼ë©´ ê²€ìƒ‰ ì‹¤í–‰
        es_results = template_data.get("es_results", [])
        if not es_results:
            es_results = await async_ES_search([user_query])

        es_context = ""
        if es_results:
            es_context += "\n[ES ìœ ì‚¬ ìƒë‹´]\n"
            for i, item in enumerate(es_results, start=1):
                es_context += f"\nğŸ“Œ [{i}ë²ˆ ìƒë‹´]\n"
                es_context += f"- ì œëª©(title): {item.get('title', '')}\n"
                es_context += f"- ì§ˆë¬¸(question): {item.get('question', '')}\n"
                es_context += f"- ë‹µë³€(answer): {item.get('answer', '')}\n"

        memory.load_memory_variables({}).get("chat_history", "")

        prompt = f"""
    ë‹¹ì‹ ì€ ë²•ë¥  ìƒë‹´ì„ ìƒì„±í•˜ëŠ” ê³ ê¸‰ AIì…ë‹ˆë‹¤.

    [ì‚¬ìš©ì ì§ˆë¬¸]
    {user_query}
    [ê°€ì¥ ì •í™•í•œ ìƒë‹´ì‚¬ë¡€]
    {es_context}

    [ìš”ì•½]
    {summary_with_links}

    [ì„¤ëª…]
    {explanation_with_links}

    [ì°¸ê³  ì§ˆë¬¸]
    {template.get("ref_question", "í•´ë‹¹ ì—†ìŒ")}

    [í•˜ì´í¼ë§í¬]
    {hyperlinks_text}

    [ì „ëµ ìš”ì•½]
    {strategy.get("final_strategy_summary", "")}

    [ì‘ë‹µ êµ¬ì„± ì „ëµ]
    - ë§íˆ¬: {strategy.get("tone", "")}
    - íë¦„: {strategy.get("structure", "")}
    - ì¡°ê±´ íë¦„ë„:
    {strategy_decision_tree}

    [ì¶”ì²œ ë§í¬]
    {json.dumps(strategy.get("recommended_links", []), ensure_ascii=False)}

    [ì¶”ê°€ëœ íŒë¡€ ìš”ì•½]
    - {precedent_summary}
    - ë§í¬: {precedent_link}
    - ì •ë³´: {precedent_meta}
    ------------------------------------------------
    ğŸ¯ ì‘ì—…:
    - ë°˜ë“œì‹œ [ê°€ì¥ ì •í™•í•œ ìƒë‹´ì‚¬ë¡€]ì˜ ì§ˆë¬¸ ë° ë‹µë³€ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ì‘ë‹µì„ ìƒì„±í•˜ì„¸ìš”.
    - ê·¸ ì™¸ì˜ ì •ë³´(ìš”ì•½, ì„¤ëª…, ì „ëµ)ëŠ” ëª¨ë‘ ì´ ìƒë‹´ì‚¬ë¡€ì— ë§ì¶° ì •ë¦¬í•´ì•¼ í•©ë‹ˆë‹¤.
    - ë‚˜ë¨¸ì§€ í•­ëª©ë“¤ì€ ì°¸ê³ ì¼ ë¿ì´ë©°, ì˜¤ì§ í•´ë‹¹ ìƒë‹´ì‚¬ë¡€ê°€ ì§„ì§œ ìƒí™©ì´ë¼ê³  ê°€ì •í•˜ì„¸ìš”.
    """
        return prompt

    async def generate_mcq_question(
        self, user_query, llm1_answer, yes_count=0, template_data=None
    ):
        prompt = await self.build_mcq_prompt_full(
            user_query, llm1_answer, template_data or {}, yes_count
        )
        response = await self.llm.ainvoke(prompt)
        return response.content.strip()

    async def ask_human(
        self, user_query, llm1_answer, current_yes_count=0, template_data=None
    ):
        # ìºì‹œëœ ì¤‘ê°„ ë°ì´í„° ì¡°íšŒ: ConversationBufferMemoryì—ì„œ ì €ì¥ëœ í…œí”Œë¦¿ ë°ì´í„° ì‚¬ìš©
        cached_data = retrieve_template_from_memory()
        # ë¹Œë“œê°€ ì™„ë£Œëœ ê²½ìš°ì—ë§Œ (built í”Œë˜ê·¸ê°€ True) ìºì‹œ ì‚¬ìš©
        if cached_data and cached_data.get("built", False):
            # print("âœ… [ìºì‹œëœ ì¤‘ê°„ ë°ì´í„° ì‚¬ìš©]")
            template_data = cached_data

        # llm1ì˜ ì´ˆê¸° ì‘ë‹µì—ì„œ "###yes" ì‹œê·¸ë„ì„ ê²€ì¶œí•˜ì—¬ yes_count ì¦ê°€
        yes_count_detected = 1 if "###yes" in llm1_answer.lower() else 0
        total_yes_count = current_yes_count + yes_count_detected

        # print("\nğŸ¤– AI: í›„ì† ì§ˆë¬¸ì„ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤...")
        mcq_q = await self.generate_mcq_question(
            user_query, llm1_answer, total_yes_count, template_data
        )

        # ë‘ ë²ˆì§¸ ì´í›„ ë‹µë³€ì—ì„œëŠ” ì €ì¥ëœ í…œí”Œë¦¿ ë°˜ì˜
        if total_yes_count >= 2:
            mcq_q = f"{mcq_q}\n\n[ì €ì¥ëœ í…œí”Œë¦¿ ì‚¬ìš©ë¨]"

        return {
            "yes_count": total_yes_count,
            "mcq_question": mcq_q,
            "is_mcq": True,
            "load_template_signal": total_yes_count >= 2,
        }


def check_user_wants_advanced_answer(user_query: str) -> bool:
    keywords = [
        "ê³ ê¸‰ ë‹µë³€",
        "ìƒì„¸í•œ ì„¤ëª…",
        "ìì„¸íˆ ì•Œë ¤ì¤˜",
        "gpt-4",
        "íŒë¡€ê¹Œì§€",
        "ì „ëµë„",
        "ê³ ê¸‰ AI",
    ]
    return any(k in user_query.lower() for k in keywords)
