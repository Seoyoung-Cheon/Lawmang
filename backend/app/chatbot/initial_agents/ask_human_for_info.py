import os
import re
from typing import Optional
from langchain_openai import ChatOpenAI
from dotenv import load_dotenv
from app.chatbot.memory.templates import get_default_strategy_template

load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")


def load_llm():
    return ChatOpenAI(
        model="gpt-3.5-turbo",
        api_key=OPENAI_API_KEY,
        temperature=0.6,
        max_tokens=512,
    )


def build_followup_prompt_ko(user_query: str, llm1_answer: str) -> str:
    return f"""
ë‹¹ì‹ ì€ ë²•ë¥  ë³´ì¡° AIì…ë‹ˆë‹¤. ë‹¤ìŒ ì‚¬ìš©ì ì§ˆë¬¸ì€ ëª¨í˜¸í•˜ê±°ë‚˜ ì •ë³´ê°€ ë¶€ì¡±í•˜ì—¬,
ë‹¹ì‹ ì€ ì‚¬ìš©ìê°€ ì¢€ ë” êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ì œê³µí•  ìˆ˜ ìˆë„ë¡ ìœ ë„ ì§ˆë¬¸ì„ ë§Œë“¤ì–´ì•¼ í•©ë‹ˆë‹¤.

â“ ì‚¬ìš©ì ì§ˆë¬¸:
{user_query}

ğŸ’¬ AI ì‘ë‹µ:
{llm1_answer}

---

ğŸ¯ ìš”ì²­ ì‘ì—…:
ì‚¬ìš©ìê°€ ë” ëª…í™•í•œ ì§ˆë¬¸ì„ í•  ìˆ˜ ìˆë„ë¡ ë„ì™€ì£¼ëŠ” â€œí›„ì† ì§ˆë¬¸â€ 1ê°œë¥¼ ìƒì„±í•˜ì„¸ìš”.
- ì§ˆë¬¸ì€ ëª…í™•í•˜ê³  êµ¬ì²´ì ì´ì–´ì•¼ í•©ë‹ˆë‹¤.
- ì‚¬ìš©ìê°€ ì‹¤ì œ ì‚¬ê±´ ì •ë³´ë¥¼ ë” ë§ì´ ë“œëŸ¬ë‚´ë„ë¡ ìœ ë„í•´ì•¼ í•©ë‹ˆë‹¤.

ì¶œë ¥:
í›„ì† ì§ˆë¬¸: [ì‘ì„±ëœ ì§ˆë¬¸]
"""


def build_mcq_prompt_ko(
    user_query: str,
    llm1_answer: str,
    strategy_summary: str = "",
    precedent_summary: str = "",
) -> str:
    return f"""
ë‹¹ì‹ ì€ ë²•ë¥  ìƒë‹´ ë³´ì¡° AIì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì´ ë‹¤ì†Œ ëª¨í˜¸í•˜ê±°ë‚˜ ì¶”ê°€ ì •ë³´ê°€ í•„ìš”í•œ ê²½ìš°,
í•´ë‹¹ ì§ˆë¬¸ì„ **ê°ê´€ì‹ ë¬¸ì œ** í˜•íƒœë¡œ ì¬êµ¬ì„±í•˜ì—¬ ì‚¬ìš©ìê°€ ìì‹ ì˜ ì˜ë„ë¥¼ ë” ëª…í™•íˆ í•˜ë„ë¡ ë„ì™€ì£¼ì„¸ìš”.

ë‹¤ìŒì€ ì‚¬ìš©ìì˜ ì›ë˜ ì§ˆë¬¸ì…ë‹ˆë‹¤:
â“ {user_query}

ë‹¤ìŒì€ ì´ì „ AI ì‘ë‹µì…ë‹ˆë‹¤ (ë¶ˆì™„ì „í•˜ê±°ë‚˜ ë‹¨í¸ì ì¼ ìˆ˜ ìˆìŒ):
ğŸ’¬ {llm1_answer}

[ì„ íƒì  ì°¸ê³  ìš”ì•½]
- ğŸ§  ì „ëµ ìš”ì•½: {strategy_summary or "í•´ë‹¹ ì—†ìŒ"}
- ğŸ“š íŒë¡€ ìš”ì•½: {precedent_summary or "í•´ë‹¹ ì—†ìŒ"}

---

ğŸ¯ ìš”ì²­ ì‘ì—…:
ìœ„ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬, **ì‚¬ìš©ìì˜ ì˜ë„ë¥¼ ë” ëª…í™•íˆ í•˜ê¸° ìœ„í•œ ê°ê´€ì‹ ì§ˆë¬¸ 1ê°œë¥¼ ìƒì„±**í•´ì£¼ì„¸ìš”.
ë‹¤ìŒ ì¡°ê±´ì„ ë°˜ë“œì‹œ ì§€ì¼œì£¼ì„¸ìš”:

- ì§ˆë¬¸ì€ ëª…í™•í•˜ê³  ì‚¬ì‹¤ì— ê·¼ê±°í•´ì•¼ í•¨
- ì„ íƒì§€ëŠ” ë°˜ë“œì‹œ 4ê°œ (A~D), ì •ë‹µì€ í•˜ë‚˜
- ë²•ë¥  ë˜ëŠ” ì‹¤ìƒí™œ ì‚¬ë¡€ì™€ ê´€ë ¨ëœ ë§¥ë½ í¬í•¨
- íŒë¡€, ë²•ë ¹, êµê³¼ì„œ ë“± ì‹ ë¢° ê°€ëŠ¥í•œ ê·¼ê±°ì— ê¸°ë°˜í•  ê²ƒ
- ë„ˆë¬´ ì‰¬ìš´ ë³´ê¸°ëŠ” í”¼í•˜ê³ , ì‹¤ì œë¡œ ê³ ë¯¼í•˜ê²Œ ë§Œë“œëŠ” ë³´ê¸° í¬í•¨

ğŸ“„ ì¶œë ¥ í˜•ì‹ì€ ë‹¤ìŒê³¼ ê°™ì•„ì•¼ í•©ë‹ˆë‹¤:

ì§ˆë¬¸: [ê°ê´€ì‹ ì§ˆë¬¸ í…ìŠ¤íŠ¸]  
A. [ì„ íƒì§€ A]  
B. [ì„ íƒì§€ B]  
C. [ì„ íƒì§€ C]  
D. [ì„ íƒì§€ D]  
ì •ë‹µ: [A/B/C/D]

â€» ì§ˆë¬¸ì€ ë°˜ë“œì‹œ **ì›ë˜ ì§ˆë¬¸ê³¼ ê´€ë ¨ì„±**ì´ ìˆì–´ì•¼ í•˜ë©°,
   ì „ëµì´ë‚˜ íŒë¡€ ìš”ì•½ì´ ìˆë‹¤ë©´ ì´ë¥¼ ì ê·¹ í™œìš©í•´ì£¼ì„¸ìš”.
"""


async def ask_human_for_information(
    user_query: str, llm1_answer: str, llm=None, user_id: Optional[str] = None
) -> dict:
    if not llm:
        llm = load_llm()

    yes_count = len(re.findall(r"###yes", llm1_answer, flags=re.IGNORECASE))
    no_count = len(re.findall(r"###no", llm1_answer, flags=re.IGNORECASE))

    is_clear = yes_count > 0
    is_ambiguous = no_count > 0 or yes_count == 0

    prompt = ""
    if is_ambiguous:
        prompt = build_followup_prompt_ko(user_query, llm1_answer)
    else:
        prompt = build_mcq_prompt_ko(
            user_query=user_query,
            llm1_answer=llm1_answer,
            strategy_summary="",  # í•„ìš”í•˜ë©´ strategy ì „ë‹¬ ê°€ëŠ¥
            precedent_summary="",  # í•„ìš”í•˜ë©´ precedent ì „ë‹¬ ê°€ëŠ¥
        )

    try:
        response = await llm.ainvoke(prompt)
        followup_question = response.content.strip()

        # yes_count ê´€ë¦¬ (ëˆ„ì  ë°©ì‹, 3ì´ìƒì´ë©´ 3ìœ¼ë¡œ ê³ ì •)
        total_yes_count = yes_count if yes_count < 3 else 3

        return {
            "followup_question": followup_question,
            "yes_count": total_yes_count,
            "is_mcq": not is_ambiguous,
        }

    except Exception as e:
        return {
            "followup_question": "ì§ˆë¬¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
            "error": str(e),
            "yes_count": 0,
            "is_mcq": False,
        }


def check_user_wants_advanced_answer(user_query: str) -> bool:
    keywords = [
        "ê³ ê¸‰ ë‹µë³€",
        "ìƒì„¸í•œ ì„¤ëª…",
        "ìì„¸íˆ ì•Œë ¤ì¤˜",
        "gpt-4",
        "íŒë¡€ê¹Œì§€",
        "ì „ëµë„",
        "ê³ ê¸‰ AI",
    ]
    return any(k in user_query.lower() for k in keywords)
