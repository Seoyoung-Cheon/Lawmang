import os
import torch
import numpy as np
import ast
from transformers import AutoTokenizer, BertModel
from sklearn.metrics.pairwise import cosine_similarity
from kiwipiepy import Kiwi  # âœ… í˜•íƒœì†Œ ë¶„ì„ê¸°
from app.core import execute_sql

# âœ… ì‚¬ìš©ì í›ˆë ¨ëœ ëª¨ë¸ ë¡œë“œ
base_dir = os.path.dirname(os.path.abspath(__file__))
model_path = os.path.join(base_dir, "20240222_best_bert_final.pth")
tokenizer = AutoTokenizer.from_pretrained("klue/bert-base")  # âœ… í•œêµ­ì–´ ì§€ì›
model = BertModel.from_pretrained("klue/bert-base")

# âœ… ëª¨ë¸ ë¡œë”©
state_dict = torch.load(model_path, map_location="cpu")
model.load_state_dict(state_dict, strict=False)
model.eval()

# âœ… í˜•íƒœì†Œ ë¶„ì„ê¸° ë¡œë“œ
kiwi = Kiwi()


def extract_keywords(text, top_k=5):
    """í˜•íƒœì†Œ ë¶„ì„ì„ í†µí•´ ëª…ì‚¬(NNG, NNP) ìƒìœ„ í‚¤ì›Œë“œ ì¶”ì¶œ"""
    tokens = kiwi.tokenize(text)
    nouns = [token.form for token in tokens if token.tag in ("NNG", "NNP")]

    keyword_freq = {word: nouns.count(word) for word in set(nouns)}
    sorted_keywords = sorted(keyword_freq, key=keyword_freq.get, reverse=True)[:top_k]

    print(f"âœ… [í‚¤ì›Œë“œ ì¶”ì¶œ ê²°ê³¼] {sorted_keywords}")
    return sorted_keywords  # âœ… í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜


# âœ… ê°œì„ ëœ BM25 ê¸°ë°˜ ê²€ìƒ‰ (plainto_tsquery ì ìš©)
def fetch_candidate_ids_bm25(table_name: str, keywords, query_text, limit=50):
    """BM25 ê¸°ë°˜ ê²€ìƒ‰ìœ¼ë¡œ ID ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°"""
    if not keywords:
        return []

    query = f"""
        SELECT id
        FROM {table_name}
        WHERE to_tsvector('simple', COALESCE(title, '') || ' ' || COALESCE(question, ''))
              @@ plainto_tsquery('simple', :query_text)
           OR {" OR ".join([f"title ILIKE :kw{i} OR question ILIKE :kw{i}" for i in range(len(keywords))])}
        ORDER BY ts_rank_cd(to_tsvector('simple', COALESCE(title, '') || ' ' || COALESCE(question, '')), 
                  plainto_tsquery('simple', :query_text)) DESC
        LIMIT :limit;
    """

    # âœ… SQL ì¸ì ìƒì„±
    params = {"query_text": query_text, "limit": limit}
    params.update({f"kw{i}": f"%{kw}%" for i, kw in enumerate(keywords)})

    result = execute_sql(query, params)
    return [row["id"] for row in result] if result else []

def fetch_vectors_by_ids(table_name: str, id_list):
    """BM25 ê²€ìƒ‰ìœ¼ë¡œ ì°¾ì€ ID ë¦¬ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë²¡í„° ê²€ìƒ‰"""
    if not id_list:
        print("âŒ ê²€ìƒ‰í•  IDê°€ ì—†ìŠµë‹ˆë‹¤.")
        return []

    placeholders = ",".join(["%s"] * len(id_list))  # âœ… `%s, %s, %s, ...` ë¬¸ìì—´ ìƒì„±
    query = f"""
        SELECT id, l_id, embedding
        FROM {table_name}
        WHERE l_id IN ({placeholders});
    """  # âœ… `IN (%s, %s, %s, ...)` ìˆ˜ë™ ìƒì„±

    result = execute_sql(query, tuple(id_list))  # âœ… ë¦¬ìŠ¤íŠ¸ë¥¼ íŠœí”Œë¡œ ë³€í™˜í•˜ì—¬ ì „ë‹¬

    vectors = []
    for row in result:
        embedding_raw = row["embedding"]

        try:
            if isinstance(embedding_raw, list):
                embedding_vector = np.array(embedding_raw)
            elif isinstance(embedding_raw, str):
                embedding_vector = np.array(ast.literal_eval(embedding_raw))
            else:
                raise ValueError(f"âŒ `embedding` ë°ì´í„° ë³€í™˜ ì‹¤íŒ¨: {embedding_raw}")

            vectors.append(
                {
                    "id": row["id"],
                    "l_id": row["l_id"],
                    "embedding": embedding_vector,
                }
            )

        except Exception as e:
            print(f"âŒ ë³€í™˜ ì‹¤íŒ¨: {e}, ë°ì´í„°: {embedding_raw}")

    return vectors


# âœ… ì‚¬ìš©ì ì…ë ¥ì„ ë²¡í„°ë¡œ ë³€í™˜
def embed_user_input(user_input: str):
    """ìœ ì € ì…ë ¥ì„ í˜•íƒœì†Œ ë¶„ì„ í›„ í‚¤ì›Œë“œë§Œ ì„ë² ë”©"""
    keywords = extract_keywords(user_input)  # âœ… í‚¤ì›Œë“œ ì¶”ì¶œ
    keyword_text = " ".join(keywords)  # âœ… í‚¤ì›Œë“œë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜

    inputs = tokenizer(keyword_text, return_tensors="pt", padding=True, truncation=True)
    with torch.no_grad():
        outputs = model(**inputs)

    embedding = outputs.last_hidden_state[:, 0, :].squeeze().numpy()  # âœ… CLS í† í° ì‚¬ìš©
    return np.array(embedding)


# âœ… ê°€ì¥ ìœ ì‚¬í•œ ë²¡í„° Top-K ì°¾ê¸° (pgvector ê¸°ë°˜)
def find_top_similar_vectors(
    user_vector, vector_data, top_k=3, similarity_threshold=0.1
):
    """ë²¡í„° ê°„ ìœ ì‚¬ë„ ê³„ì‚°í•˜ì—¬ Top-K ì°¾ê¸°"""
    embeddings = np.array([v["embedding"] for v in vector_data])
    similarities = cosine_similarity([user_vector], embeddings)[0]

    sorted_indices = np.argsort(similarities)[::-1]  # âœ… ìœ ì‚¬ë„ê°€ ë†’ì€ ìˆœì„œë¡œ ì •ë ¬
    top_results = []

    for idx in sorted_indices[:top_k]:
        if similarities[idx] >= similarity_threshold:
            top_results.append((vector_data[idx], similarities[idx]))

    return top_results


# âœ… ì‹¤ì œ ë²•ë¥  ìƒë‹´ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜
def fetch_consultation_content(l_id: int):
    query = """
        SELECT title, question, answer
        FROM legal_consultation
        WHERE id = :l_id;
    """
    result = execute_sql(query, {"l_id": l_id}, fetch_one=True)
    return result if result else None


# âœ… ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ (pgvector + BM25 ê²°í•©)
def main(user_input):
    print(f"ğŸ“Œ ìœ ì € ì…ë ¥: {user_input}")

    # âœ… 1. í‚¤ì›Œë“œ ì¶”ì¶œ
    keywords = extract_keywords(user_input)

    # âœ… 2. BM25 + LIKE ê²€ìƒ‰ ì‹¤í–‰
    candidate_ids = fetch_candidate_ids_bm25(
        "legal_consultation", keywords, user_input, limit=50
    )

    if not candidate_ids:
        print("âŒ BM25 ê²€ìƒ‰ì—ì„œ í›„ë³´êµ°ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    # âœ… 3. ë²¡í„° ê°€ì ¸ì˜¤ê¸°
    candidate_vectors = fetch_vectors_by_ids("vectorized_consultation", candidate_ids)

    if not candidate_vectors:
        print("âŒ ë²¡í„° í…Œì´ë¸”ì—ì„œ ìœ ì‚¬í•œ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    # âœ… 4. ì‚¬ìš©ì ì…ë ¥ ë²¡í„° ë³€í™˜
    user_vector = embed_user_input(user_input)

    # âœ… 5. ë²¡í„° ê²€ìƒ‰ ìˆ˜í–‰
    top_similar_vectors = find_top_similar_vectors(
        user_vector, candidate_vectors, top_k=3, similarity_threshold=0.1
    )

    if not top_similar_vectors:
        print("âŒ ë²¡í„° ê²€ìƒ‰ì—ì„œ ìœ ì‚¬í•œ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    print("\nğŸ“Œ [ìƒë‹´ ë°ì´í„°] ìœ ì‚¬ë„ê°€ ë†’ì€ ê²°ê³¼ (Top-K):")
    for i, (best_vector, similarity) in enumerate(top_similar_vectors):
        original_content = fetch_consultation_content(best_vector["l_id"])
        print(
            f"ğŸ“Œ ì œëª©: {original_content['title']}\nğŸ“Œ ì§ˆë¬¸: {original_content['question']}\nğŸ“Œ ë‹µë³€: {original_content['answer']}"
        )

if __name__ == "__main__":
    user_input = "ë¶€ë™ì‚° ì‚¬ê¸°ë¥¼ ë‹¹í–ˆìŠµë‹ˆë‹¤ ì–´ë–»ê²Œ ëŒ€ì‘í• ê¹Œìš”?"
    main(user_input)