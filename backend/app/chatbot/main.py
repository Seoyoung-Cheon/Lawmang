import os
import sys
import asyncio
from asyncio import Lock
from dotenv import load_dotenv

from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from app.chatbot.tool_agents.executor.normalanswer import run_final_answer_generation
from app.chatbot.initial_agents.controller import run_initial_controller
from app.chatbot.tool_agents.controller import run_full_consultation
from app.chatbot.tool_agents.utils.utils import faiss_kiwi

# âœ… ë½: ì¤‘ë³µ ì‹¤í–‰ ë°©ì§€
llm2_lock = Lock()
yes_count = 0
executed_once = False

sys.path.append(os.path.abspath("."))
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
DB_FAISS_PATH = "./app/chatbot/faiss"


def load_faiss():
    try:
        embedding_model = OpenAIEmbeddings(
            model="text-embedding-ada-002",
            openai_api_key=OPENAI_API_KEY,
        )
        return FAISS.load_local(
            DB_FAISS_PATH,
            embedding_model,
            allow_dangerous_deserialization=True,
        )
    except Exception as e:
        print(f"âŒ FAISS ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None
    
    
async def run_dual_pipeline(user_query: str):
    global yes_count
    print(f"\nğŸ” ì‚¬ìš©ì ì§ˆë¬¸ ìˆ˜ì‹ : {user_query}")

    faiss_db = load_faiss()
    if not faiss_db:
        return {"error": "FAISS ë¡œë“œ ì‹¤íŒ¨"}

    # âœ… ì´ˆê¸° ì‘ë‹µ ë¨¼ì € ì‹¤í–‰ (íŒë‹¨ ê¸°ë°˜ìœ¼ë¡œ ë¶„ê¸°)
    initial_result = await run_initial_controller(
        user_query, faiss_db, current_yes_count=yes_count
    )
    status = initial_result.get("status", "ok")

    # âœ… ë¹„ë²•ë¥  / ì°¨ë‹¨ ì¡°ê±´: ê³ ê¸‰ ì‹¤í–‰ ì°¨ë‹¨
    if status in ["no_triggered", "nonlegal_skipped"]:
        return {"initial": initial_result, "advanced": None}

    # âœ… YES ì¹´ìš´íŠ¸ ì—…ë°ì´íŠ¸
    yes_count = initial_result.get("yes_count", yes_count)

    # âœ… ì „ë ¥/íŒë¡€ ë¹Œë“œ ì¡°ê±´ë¶€ ì‹¤í–‰
    search_keywords = faiss_kiwi.extract_top_keywords_faiss(user_query, faiss_db)
    prepared_data = await run_full_consultation(
        user_query, search_keywords, build_only=True
    )
    template = prepared_data.get("template")
    strategy = prepared_data.get("strategy")
    precedent = prepared_data.get("precedent")

    if not all([template, strategy, precedent]):
        print("âš ï¸ ì „ë ¥ ë˜ëŠ” íŒë¡€ ë¹Œë“œ ì‹¤íŒ¨. ê³ ê¸‰ ì‘ë‹µ ìƒëµ")
        return {"initial": initial_result, "advanced": None}

    advanced_result = None
    if yes_count >= 3:
        async with llm2_lock:
            print("ğŸš€ [YES ì¡°ê±´ ë§Œì¡± â†’ GPT ê³ ê¸‰ ì‘ë‹µ ìƒì„± ì‹œì‘]")

            final_answer = run_final_answer_generation(
                template=template,
                strategy=strategy,
                precedent=precedent,
                user_query=user_query,
                model="gpt-4",
            )

            # âœ… ì¹´ìš´íŠ¸ ì´ˆê¸°í™” (3 â†’ 1)
            yes_count = 1

            advanced_result = {
                "user_query": user_query,
                "template": template,
                "strategy": strategy,
                "precedent": precedent,
                "final_answer": final_answer,
                "status": "ok",
            }
    else:
        print(f"â¸ï¸ [ê³ ê¸‰ ì‘ë‹µ ì¡°ê±´ ë¯¸ë‹¬ - í˜„ì¬ yes_count: {yes_count}]")

    return {
        "initial": initial_result,
        "advanced": advanced_result,
    }


async def chatbot_loop():
    print("âœ… [ì‹œì‘] ë²•ë¥  AI ì±—ë´‡")

    while True:
        user_query = input("\nâ“ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì¢…ë£Œ: exit): ")
        if user_query.lower() == "exit":
            break

        if llm2_lock.locked():
            print("âš ï¸ [ê³ ê¸‰ ì‘ë‹µ ìƒì„± ì¤‘, ì ì‹œë§Œ ê¸°ë‹¤ë¦¬ì„¸ìš”.]")
            continue

        result = await run_dual_pipeline(user_query)

        if "error" in result:
            print("âŒ ì‹¤í–‰ ì‹¤íŒ¨:", result["error"])
            continue

        initial = result["initial"]

        print("\nğŸŸ¦ [ì´ˆê¸° LLM ì‘ë‹µ]:")
        print(initial.get("initial_response", "ì‘ë‹µ ì—†ìŒ"))

        followup = initial.get("followup_question")
        is_mcq = initial.get("is_mcq", False)

        if followup:
            if is_mcq and isinstance(followup, dict):
                print("\nğŸŸ¨ [ê°ê´€ì‹ í›„ì† ì§ˆë¬¸ ì œì•ˆ]:")
                print("ğŸ“Œ ì§ˆë¬¸:", followup.get("question", "ì—†ìŒ"))
                for key, value in followup.get("options", {}).items():
                    print(f"   {key}. {value}")
                print("âœ… ì •ë‹µ:", followup.get("correct_answer", "ì—†ìŒ"))
            else:
                print("\nğŸŸ¨ [í›„ì† ì§ˆë¬¸ ì œì•ˆ]:", followup)

        advanced = result.get("advanced")
        if advanced:
            if advanced.get("final_answer"):
                print("\nğŸš€ [ê³ ê¸‰ LLM ì‘ë‹µ]:")
                print(
                    "ğŸ“„ í…œí”Œë¦¿ ìš”ì•½:",
                    advanced.get("template", {}).get("summary", "ì—†ìŒ"),
                )
                print(
                    "ğŸ§  ì „ëµ ìš”ì•½:",
                    advanced.get("strategy", {}).get("final_strategy_summary", "ì—†ìŒ"),
                )
                print(
                    "ğŸ“š íŒë¡€ ìš”ì•½:",
                    advanced.get("precedent", {}).get("summary", "ì—†ìŒ"),
                )
                print(
                    "ğŸ”— ë§í¬:",
                    advanced.get("precedent", {}).get("casenote_url", "ì—†ìŒ"),
                )
                print("\nğŸ¤– ìµœì¢… GPT ì‘ë‹µ:\n", advanced.get("final_answer", "ì—†ìŒ"))
            else:
                print("ğŸ”§ [ì „ëµ/íŒë¡€ ë¹Œë“œ ì™„ë£Œ (ìµœì¢… GPT ì‘ë‹µ ìƒëµë¨)]")
        else:
            print("\nâœ… ì´ˆê¸° ì‘ë‹µìœ¼ë¡œ ì¶©ë¶„í•©ë‹ˆë‹¤.")


def main():
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    loop.run_until_complete(chatbot_loop())
    loop.close()


if __name__ == "__main__":
    main()
