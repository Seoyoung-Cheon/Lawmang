# from langchain.chat_models import ChatOpenAI
# from langchain.prompts import PromptTemplate

# llm = ChatOpenAI(model_name="gpt-4")


# def generate_search_keywords(user_query):
#     prompt = PromptTemplate.from_template(
#         "ì‚¬ìš©ìê°€ '{query}'ë¼ê³  ì§ˆë¬¸í–ˆìŠµë‹ˆë‹¤. ê°€ì¥ ê´€ë ¨ì„±ì´ ë†’ì€ í‚¤ì›Œë“œ 5ê°œë¥¼ ìƒì„±í•˜ì„¸ìš”."
#     )
#     response = llm.predict(prompt.format(query=user_query))
#     return response.split()
# from langchain.vectorstores import FAISS
# from langchain.embeddings import OpenAIEmbeddings

# faiss_db = FAISS.load_local("faiss_index", OpenAIEmbeddings())


# def search_documents(query):
#     results = faiss_db.similarity_search(query, k=5)
#     return results
# def verify_search_results(results):
#     """
#     ê²€ìƒ‰ ê²°ê³¼ì˜ í’ˆì§ˆì„ í‰ê°€í•˜ì—¬ Self-Reflection ìˆ˜í–‰
#     """
#     llm_prompt = (
#         f"ê²€ìƒ‰ ê²°ê³¼: {results}\nì´ ë¬¸ì„œë“¤ì´ ì§ˆë¬¸ê³¼ ê´€ë ¨ ìˆëŠ”ì§€ í‰ê°€í•˜ì„¸ìš”. (Yes / No)"
#     )
#     verification = llm.predict(llm_prompt)

#     if "No" in verification:
#         return False  # ğŸ”„ í‚¤ì›Œë“œ ìˆ˜ì • í›„ ì¬ê²€ìƒ‰ í•„ìš”
#     return True  # âœ… ê²€ìƒ‰ ê²°ê³¼ ì‚¬ìš© ê°€ëŠ¥
# def generate_follow_up_question(user_query):
#     prompt = PromptTemplate.from_template(
#         "ì‚¬ìš©ìì˜ ì§ˆë¬¸ '{query}'ì´(ê°€) ê²€ìƒ‰ ê²°ê³¼ì™€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì¶”ê°€ì ìœ¼ë¡œ ë¬¼ì–´ë³¼ ì§ˆë¬¸ì„ ìƒì„±í•˜ì„¸ìš”."
#     )
#     follow_up = llm.predict(prompt.format(query=user_query))
#     return follow_up
# from langchain.chains import RetrievalQA

# qa_chain = RetrievalQA.from_chain_type(llm, retriever=faiss_db.as_retriever())


# def generate_final_answer(query):
#     return qa_chain.run(query)
# def self_rag_pipeline(user_query):
#     print(f"ğŸ” ì‚¬ìš©ì ì§ˆë¬¸: {user_query}")

#     # 1ï¸âƒ£ ê²€ìƒ‰ í‚¤ì›Œë“œ ìƒì„±
#     search_keywords = generate_search_keywords(user_query)
#     print(f"âœ… ìƒì„±ëœ ê²€ìƒ‰ í‚¤ì›Œë“œ: {search_keywords}")

#     # 2ï¸âƒ£ FAISS ê¸°ë°˜ ê²€ìƒ‰
#     search_results = search_documents(" ".join(search_keywords))
#     print(f"ğŸ” ì´ˆê¸° ê²€ìƒ‰ ê²°ê³¼: {search_results}")

#     # 3ï¸âƒ£ ê²€ìƒ‰ ê²°ê³¼ ìì²´ ê²€ì¦
#     if not verify_search_results(search_results):
#         print("âš  ê²€ìƒ‰ ê²°ê³¼ ë¶€ì¡± â†’ í‚¤ì›Œë“œ ìˆ˜ì • í›„ ì¬ê²€ìƒ‰")
#         search_keywords = generate_search_keywords(user_query + " ì¶”ê°€ ê²€ìƒ‰")
#         search_results = search_documents(" ".join(search_keywords))

#     # 4ï¸âƒ£ ì¶”ê°€ ì§ˆë¬¸ í•„ìš” ì—¬ë¶€ í™•ì¸
#     if not search_results:
#         follow_up_question = generate_follow_up_question(user_query)
#         print(f"â“ ì¶”ê°€ ì§ˆë¬¸ ìš”ì²­: {follow_up_question}")
#         return follow_up_question

#     # 5ï¸âƒ£ ìµœì¢… ì‘ë‹µ ìƒì„±
#     final_answer = generate_final_answer(user_query)
#     print(f"ğŸ¤– ìµœì¢… ë‹µë³€: {final_answer}")

#     return final_answer
