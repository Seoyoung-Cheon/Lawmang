# planner.py

import json
import openai
from tools import LawGoKRTavilySearch

openai.api_key = "YOUR_OPENAI_API_KEY"


async def generate_response_template(
    title: str,
    question: str,
    answer: str,
    user_query: str,
    model: str = "gpt-3.5-turbo",
) -> dict:
    """
    ğŸ“Œ ì„ íƒëœ ìƒë‹´(title, question, answer)ì„ ë°”íƒ•ìœ¼ë¡œ,
    LLMì´ ì‰½ê²Œ í™œìš©í•  ìˆ˜ ìˆëŠ” ì‘ë‹µ í…œí”Œë¦¿(summary, explanation, ë§í¬ ë“±)ì„ êµ¬ì„±.
    """

    prompt = f"""
ë‹¹ì‹ ì€ ë²•ë¥  ìƒë‹´ ì‘ë‹µ í…œí”Œë¦¿ì„ êµ¬ì„±í•˜ëŠ” AIì…ë‹ˆë‹¤.

ì‚¬ìš©ìì˜ ì§ˆë¬¸:
"{user_query}"

ìƒë‹´ ì£¼ì œ(title):
"{title}"

ìƒë‹´ ì§ˆë¬¸(question):
"{question}"

ìƒë‹´ ë‹µë³€(answer):
"{answer}"

--- ì‘ì—… ì§€ì‹œ ---
1. ì‚¬ìš©ìê°€ ì´í•´í•˜ê¸° ì‰½ê²Œ í•µì‹¬ ë‚´ìš©ì„ ìš”ì•½í•˜ì„¸ìš” (summary).
2. ìš”ì•½ì„ ë°”íƒ•ìœ¼ë¡œ, ìƒë‹´ ë‹µë³€ì˜ ë‚´ìš©ì„ ì¼ë°˜ì¸ì´ ì´í•´í•  ìˆ˜ ìˆë„ë¡ í’€ì–´ì„œ ì„¤ëª…í•˜ì„¸ìš” (explanation).
3. ë‹µë³€ê³¼ ê´€ë ¨ëœ ë²•ë ¹/íŒë¡€ê°€ ìˆë‹¤ë©´ í•˜ì´í¼ë§í¬ í˜•íƒœë¡œ ì œê³µí•˜ì„¸ìš”. labelê³¼ urlì„ í¬í•¨í•œ ë¦¬ìŠ¤íŠ¸ í˜•ì‹ (hyperlinks).
4. ê·¸ë¦¬ê³  ì´ ìƒë‹´ì—ì„œ ì‚¬ìš©ëœ `question`ì€ ì°¸ê³ ìš© ì§ˆë¬¸ì´ë¯€ë¡œ 'ref_question'ì´ë¼ëŠ” keyë¡œ ë°˜í™˜í•˜ì„¸ìš”.

--- ì‘ë‹µ ì˜ˆì‹œ ---
{{
  "summary": "...",
  "explanation": "...",
  "hyperlinks": [{{"label": "...", "url": "..."}}], 
  "ref_question": "..."
}}

ë°˜ë“œì‹œ ìœ„ JSON í˜•ì‹ ê·¸ëŒ€ë¡œ ì‘ë‹µí•˜ì„¸ìš”.
"""

    response = openai.ChatCompletion.create(
        model=model,
        messages=[
            {
                "role": "system",
                "content": "ë‹¹ì‹ ì€ ë²•ë¥  ì‘ë‹µ í…œí”Œë¦¿ì„ ìƒì„±í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.",
            },
            {"role": "user", "content": prompt},
        ],
        temperature=0.3,
    )

    result_text = response.choices[0].message["content"]
    print("âœ… [ì‘ë‹µ í…œí”Œë¦¿ ê²°ê³¼]:", result_text)


    try:
        return json.loads(result_text)
    except Exception as e:
        print("âŒ JSON íŒŒì‹± ì˜¤ë¥˜:", e)
        return {"error": "GPT ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨"}

# planner.py ë‚´ë¶€

async def evaluate_strategy_with_tavily(
    strategy: dict, tavily_results: list, model: str = "gpt-3.5-turbo"
) -> dict:
    """
    ğŸ“Œ Tavilyì—ì„œ ê°€ì ¸ì˜¨ ì—¬ëŸ¬ ìš”ì•½ê³¼ ì „ëµì„ ë¹„êµí•˜ì—¬,
    ì „ëµì´ ë¶€ì‹¤í•˜ë©´ needs_revision: Trueë¡œ íŒë‹¨
    """

    if not tavily_results or not isinstance(tavily_results, list):
        return {
            "needs_revision": False,
            "reason": "Tavily ê²°ê³¼ê°€ ì—†ê±°ë‚˜ ìœ íš¨í•˜ì§€ ì•Šì•„ ì „ëµ í‰ê°€ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.",
            "tavily_snippets": [],
        }

    # ìµœëŒ€ 3ê°œì˜ ìš”ì•½ ì¶”ì¶œ
    tavily_snippets = []
    for result in tavily_results[:3]:
        text = result.get("content") or result.get("snippet") or result.get("text")
        if text:
            tavily_snippets.append(text.strip())

    if not tavily_snippets:
        return {
            "needs_revision": False,
            "reason": "Tavilyì—ì„œ ìœ ì˜ë¯¸í•œ ìš”ì•½ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
            "tavily_snippets": [],
        }

    # Tavily ìš”ì•½ ë‚´ìš© í•˜ë‚˜ë¡œ í•©ì¹˜ê¸°
    combined_snippets = "\n\n".join(
        [f"[ìš”ì•½ {i + 1}]\n{text}" for i, text in enumerate(tavily_snippets)]
    )

    prompt = f"""
ë‹¹ì‹ ì€ ë²•ë¥  ìƒë‹´ ì „ëµì„ í‰ê°€í•˜ëŠ” AIì…ë‹ˆë‹¤.

[GPT ì „ëµ ìš”ì•½]
{strategy.get("final_strategy_summary", "")}

[Tavily ìš”ì•½ ê²°ê³¼ë“¤]
{combined_snippets}

--- ì‘ì—… ì§€ì‹œ ---
Tavily ìš”ì•½ 1~3ê°œë¥¼ ëª¨ë‘ ì°¸ê³ í•˜ì—¬, GPT ì „ëµì´ ë¶€ì‹¤í•˜ê±°ë‚˜ ì¤‘ìš”í•œ ì •ë³´ë¥¼ ëˆ„ë½í–ˆëŠ”ì§€ í‰ê°€í•˜ì„¸ìš”.  

- Tavily ìš”ì•½ë“¤ì´ ë²•ë ¹/ì¡°í•­/í•µì‹¬ ë¬¸ì¥ì„ ë‹´ê³  ìˆëŠ”ë° ì „ëµì—ì„œ ì´ë¥¼ ë‹¤ë£¨ì§€ ì•Šìœ¼ë©´ ë¶€ì‹¤í•©ë‹ˆë‹¤.
- ì „ëµì´ ë„ˆë¬´ ì¶”ìƒì ì´ê±°ë‚˜ ì• ë§¤í•˜ë©´ ë³´ì™„ì´ í•„ìš”í•©ë‹ˆë‹¤.

ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”:

{{
  "needs_revision": true or false,
  "reason": "...",
  "tavily_snippets": [...]
}}
"""

    response = openai.ChatCompletion.create(
        model=model,
        messages=[
            {
                "role": "system",
                "content": "ë‹¹ì‹ ì€ GPT ì „ëµê³¼ ë²•ë¥  ìš”ì•½ì˜ ì§ˆì  ì°¨ì´ë¥¼ í‰ê°€í•˜ëŠ” ë²•ë¥  ë¶„ì„ê°€ì…ë‹ˆë‹¤.",
            },
            {"role": "user", "content": prompt},
        ],
        temperature=0.2,
    )

    result_text = response.choices[0].message["content"]
    print("âœ… [Tavily ê¸°ë°˜ ì „ëµ í‰ê°€ ê²°ê³¼]:", result_text)

    try:
        return json.loads(result_text)
    except Exception as e:
        print("âŒ JSON íŒŒì‹± ì‹¤íŒ¨:", e)
        return {
            "needs_revision": False,
            "reason": "GPT ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨",
            "tavily_snippets": tavily_snippets,
        }


async def revise_strategy_with_feedback(
    original_strategy: dict,
    tavily_snippets: list,
    model: str = "gpt-3.5-turbo",
) -> dict:
    """
    ğŸ“Œ ì „ëµì´ ë¶€ì¡±í•˜ë‹¤ê³  íŒë‹¨ë˜ì—ˆì„ ê²½ìš°, Tavily ìš”ì•½ì„ ì°¸ê³ í•´ ì „ëµì„ ë³´ì™„
    """
    combined_snippets = "\n\n".join(
        [
            f"[Tavily ìš”ì•½ {i + 1}]\n{snippet}"
            for i, snippet in enumerate(tavily_snippets)
        ]
    )

    prompt = f"""
GPTê°€ ë§Œë“  ê¸°ì¡´ ì „ëµì´ ë„ˆë¬´ ëª¨í˜¸í•˜ê±°ë‚˜ í•µì‹¬ ì •ë³´ë¥¼ ëˆ„ë½í•œ ê²ƒìœ¼ë¡œ íŒë‹¨ë©ë‹ˆë‹¤.  
ì•„ë˜ Tavily ìš”ì•½ì„ ì°¸ê³ í•˜ì—¬ ì „ëµì„ ë³´ì™„í•˜ì„¸ìš”.

[Tavily ìš”ì•½ë“¤]
{combined_snippets}

[ê¸°ì¡´ ì „ëµ ìš”ì•½]
{original_strategy.get("final_strategy_summary", "")}

--- ì‘ì—… ì§€ì‹œ ---
- ê¸°ì¡´ ì „ëµì„ ê¸°ë°˜ìœ¼ë¡œ í•˜ë˜, Tavilyì˜ ë²•ë ¹ ìš”ì•½ì„ ë°˜ì˜í•˜ì—¬ ë” ëª…í™•í•˜ê²Œ ìˆ˜ì •í•˜ì„¸ìš”.
- ì „ì²´ ì „ëµ JSON êµ¬ì¡°ëŠ” ìœ ì§€í•˜ì„¸ìš”.

ì‘ë‹µ í˜•ì‹ (JSON):
{{
  "tone": "...",
  "structure": "...",
  "decision_tree": ["..."],
  "final_strategy_summary": "...",
  "recommended_links": [{{"label": "...", "url": "..."}}]
}}
"""

    response = openai.ChatCompletion.create(
        model=model,
        messages=[
            {
                "role": "system",
                "content": "ë‹¹ì‹ ì€ ì „ëµì„ ë³´ì™„í•˜ëŠ” ë²•ë¥  ì‘ë‹µ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.",
            },
            {"role": "user", "content": prompt},
        ],
        temperature=0.2,
    )

    result_text = response.choices[0].message["content"]
    print("âœ… [ì „ëµ ë³´ì™„ ê²°ê³¼]:", result_text)

    try:
        return json.loads(result_text)
    except Exception as e:
        print("âŒ ì „ëµ ë³´ì™„ íŒŒì‹± ì‹¤íŒ¨:", e)
        return {"error": "GPT ì „ëµ ë³´ì™„ ì‹¤íŒ¨"}

async def generate_response_strategy(
    explanation: str,
    user_query: str,
    hyperlinks: list = None,
    model: str = "gpt-3.5-turbo",
) -> dict:
    """
    ğŸ“Œ ì„¤ëª… ì´ˆì•ˆì„ ê¸°ë°˜ìœ¼ë¡œ ì „ëµ ì„¤ê³„ + Tavily í‰ê°€ê¹Œì§€ ìë™ ìˆ˜í–‰
    """
    hyperlinks = hyperlinks or []

    hyperlink_text = (
        "\n".join([f"- {item['label']}: {item['url']}" for item in hyperlinks])
        if hyperlinks
        else "ì—†ìŒ"
    )

    # 1ï¸âƒ£ ì „ëµ ì„¤ê³„ í”„ë¡¬í”„íŠ¸
    prompt = f"""
ë‹¹ì‹ ì€ ë²•ë¥  ì‘ë‹µ ì „ëµì„ ì„¤ê³„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

[ì‚¬ìš©ì ì§ˆë¬¸]
"{user_query}"

[ì„¤ëª… ì´ˆì•ˆ]
"{explanation}"

[ê´€ë ¨ ë²•ë¥  ë§í¬]
{hyperlink_text}

--- ì‘ì—… ì§€ì‹œ ---
1. ì‚¬ìš©ì ê²½í—˜ì„ ê³ ë ¤í•´ ì ì ˆí•œ ë§íˆ¬(tone/style)ë¥¼ ì„¤ê³„í•˜ì„¸ìš”.  
2. ì‘ë‹µ íë¦„ êµ¬ì¡°ë¥¼ ì„¤ëª…í•˜ì„¸ìš”.  
3. ì¡°ê±´/ì˜ˆì™¸ íë¦„ì´ ìˆë‹¤ë©´ decision_tree í˜•ì‹ìœ¼ë¡œ ë§Œë“œì„¸ìš”.  
4. ì „ì²´ ì „ëµì„ ìš”ì•½í•˜ì„¸ìš”.  
5. ì¶”ì²œ ë§í¬ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ì •ë¦¬í•˜ì„¸ìš”.

ì‘ë‹µ í˜•ì‹ (JSON):
{{
  "tone": "...",
  "structure": "...",
  "decision_tree": ["..."],
  "final_strategy_summary": "...",
  "recommended_links": [{{"label": "...", "url": "..."}}]
}}
"""

    # 2ï¸âƒ£ ì „ëµ ìƒì„±
    response = openai.ChatCompletion.create(
        model=model,
        messages=[
            {"role": "system", "content": "ë‹¹ì‹ ì€ ë²•ë¥  ìƒë‹´ ì „ëµì„ ì„¤ê³„í•˜ëŠ” AIì…ë‹ˆë‹¤."},
            {"role": "user", "content": prompt},
        ],
        temperature=0.3,
    )

    strategy_raw = response.choices[0].message["content"]
    print("âœ… [ì „ëµ ì„¤ê³„ ê²°ê³¼]:", strategy_raw)

    try:
        strategy = json.loads(strategy_raw)
    except Exception as e:
        print("âŒ ì „ëµ íŒŒì‹± ì‹¤íŒ¨:", e)
        return {"error": "GPT ì „ëµ íŒŒì‹± ì‹¤íŒ¨"}


    # 3ï¸âƒ£ Tavily í‰ê°€ ìë™ í¬í•¨
    search_tool = LawGoKRTavilySearch(max_results=3)
    tavily_results = search_tool.run(user_query)

    evaluation = await evaluate_strategy_with_tavily(strategy, tavily_results)

    # í‰ê°€ ê²°ê³¼ ì¶”ê°€
    strategy["evaluation"] = evaluation

    return strategy


async def run_response_strategy_with_limit(
    explanation, user_query, hyperlinks, model="gpt-3.5-turbo"
):
    """
    ğŸ“Œ ì „ëµ ìƒì„± í›„, Tavily í‰ê°€ â†’ í•„ìš”ì‹œ 1íšŒ ë³´ì™„ë§Œ í—ˆìš©
    """
    # 1ï¸âƒ£ ì „ëµ ìƒì„±
    strategy = await generate_response_strategy(
        explanation, user_query, hyperlinks, model
    )

    evaluation = strategy.get("evaluation", {})
    if evaluation.get("needs_revision") is True:
        print("âš ï¸ ì „ëµ ë³´ì™„ ìš”ì²­ ê°ì§€ â†’ 1íšŒì— í•œí•´ ë³´ì™„í•©ë‹ˆë‹¤.")
        revised = await revise_strategy_with_feedback(
            original_strategy=strategy,
            tavily_snippets=evaluation.get("tavily_snippets", []),
        )
        revised["evaluation"] = {"revised": True}
        return revised

    return strategy
