import os
import torch
import numpy as np
import ast
from sklearn.metrics.pairwise import cosine_similarity
from transformers import BertModel, BertTokenizer
from app.core import execute_sql

# ëª¨ë¸ ë¡œë“œ (ë¡œì»¬ BERT ëª¨ë¸)
base_dir = os.path.dirname(os.path.abspath(__file__))
model_path = os.path.join(base_dir, "20240222_best_bert_final.pth")


# ê°œì¡°í•œ BERT ëª¨ë¸ ì •ì˜
class CustomBERTModel(torch.nn.Module):
    def __init__(self):
        super().__init__()
        self.bert = BertModel.from_pretrained("bert-base-uncased")

    def forward(self, input_ids, attention_mask=None, token_type_ids=None):
        return self.bert(
            input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids
        )


# ëª¨ë¸ ë¡œë”©
model = CustomBERTModel()
state_dict = torch.load(model_path, map_location="cpu")
new_state_dict = {k.replace("bert.", ""): v for k, v in state_dict.items()}
model.load_state_dict(new_state_dict, strict=False)
model.eval()

# í† í¬ë‚˜ì´ì € ë¡œë”©
tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")


# ì‚¬ìš©ì ì…ë ¥ì„ ë²¡í„°ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
def embed_user_input(user_input: str):
    inputs = tokenizer(user_input, return_tensors="pt", padding=True, truncation=True)
    with torch.no_grad():
        outputs = model(**inputs)
    embedding = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()
    return np.array(embedding)


# ë²¡í„° DBì—ì„œ ì„ë² ë”©ëœ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜ (ì—¬ëŸ¬ ê°œ ë°˜í™˜)
def fetch_vectors(table_name: str, limit=50):
    query = f"""
        SELECT id, l_id, embedding
        FROM {table_name}
        LIMIT :limit;
    """
    params = {"limit": limit}
    result = execute_sql(query, params)

    vectors = []
    for row in result:
        embedding_raw = row["embedding"]
        if isinstance(embedding_raw, str):
            embedding_vector = np.array(ast.literal_eval(embedding_raw))
        else:
            embedding_vector = np.array(embedding_raw)

        vectors.append(
            {
                "id": row["id"],
                "l_id": row["l_id"],
                "embedding": embedding_vector,
            }
        )
    return vectors


# ê°€ì¥ ìœ ì‚¬í•œ ì—¬ëŸ¬ ê°œì˜ ë²¡í„° ì°¾ê¸° (Top-K + ìœ ì‚¬ë„ ê¸°ì¤€ ì ìš©)
def find_top_similar_vectors(
    user_vector, vector_data, top_k=3, similarity_threshold=0.5
):
    embeddings = np.array([v["embedding"] for v in vector_data])
    similarities = cosine_similarity([user_vector], embeddings)[0]

    # âœ… Top-K ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
    sorted_indices = np.argsort(similarities)[::-1]  # ìœ ì‚¬ë„ê°€ ë†’ì€ ìˆœì„œë¡œ ì •ë ¬
    top_results = []

    for idx in sorted_indices[:top_k]:
        if similarities[idx] >= similarity_threshold:
            top_results.append((vector_data[idx], similarities[idx]))

    return top_results


# ì‹¤ì œ ë²•ë¥  ìƒë‹´ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜
def fetch_consultation_content(l_id: int):
    query = """
        SELECT title, question, answer
        FROM legal_consultation
        WHERE id = :l_id;
    """
    result = execute_sql(query, {"l_id": l_id}, fetch_one=True)
    return result if result else None


# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
def main(user_input):
    print(f"ğŸ“Œ ìœ ì € ì…ë ¥: {user_input}")

    user_vector = embed_user_input(user_input)
    vectors = fetch_vectors("vectorized_consultation", limit=100)  # âœ… ê²€ìƒ‰ ë²”ìœ„ í™•ëŒ€

    top_similar_vectors = find_top_similar_vectors(
        user_vector, vectors, top_k=3, similarity_threshold=0.5
    )

    if not top_similar_vectors:
        print("âŒ ìœ ì‚¬í•œ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    print("\nğŸ“Œ [ìƒë‹´ ë°ì´í„°] ìœ ì‚¬ë„ê°€ ë†’ì€ ê²°ê³¼ (Top-K):")
    for i, (best_vector, similarity) in enumerate(top_similar_vectors):
        print(f"\nğŸ”¹ ê²°ê³¼ {i + 1}")
        print(
            f"ID: {best_vector['id']}, l_id: {best_vector['l_id']}, ìœ ì‚¬ë„: {similarity:.4f}"
        )

        original_content = fetch_consultation_content(best_vector["l_id"])
        if original_content:
            print(f"ğŸ“Œ ì œëª©: {original_content['title']}")
            print(f"ğŸ“Œ ì§ˆë¬¸: {original_content['question']}")
            print(f"ğŸ“Œ ë‹µë³€: {original_content['answer']}")
        else:
            print("âŒ ì›ë³¸ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")


if __name__ == "__main__":
    user_input = "ë¶€ë™ì‚° ì‚¬ê¸°ë¥¼ ë‹¹í–ˆìŠµë‹ˆë‹¤ ì–´ë–»ê²Œ ëŒ€ì‘í• ê¹Œìš”?"
    main(user_input)
